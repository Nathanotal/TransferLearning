{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install torch\n",
    "# %pip install torchvision\n",
    "# %pip install helper\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Maybe normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as tttttt\n",
    "import random\n",
    "\n",
    "random.seed(5)\n",
    "np.random.seed(100)\n",
    "\n",
    "def open_image(path): # https://jovian.ai/aakashns/transfer-learning-pytorch\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.standardImagesAdded = 0\n",
    "        self.length = len(subset.dataset)\n",
    "        self.subset = subset # th.utils.data.ConcatDataset([subset, subset]) # Add data\n",
    "        self.transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                            # transforms.RandomRotation(degrees=(-30, 30)),\n",
    "                                            # transforms.Resize(255),\n",
    "                                            # transforms.CenterCrop(224), \n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]) # normalization ABC\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if ((self.standardImagesAdded % self.length*2) < self.length): # Add standard images\n",
    "            self.standardImagesAdded += 1\n",
    "            return self.subset[index]\n",
    "        \n",
    "        # Add augmented images\n",
    "        x, y = self.subset[index]\n",
    "        t = tttttt.ToPILImage()\n",
    "        x = self.transform(t(x)) \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, binary=False, limit=1, train=True):\n",
    "        super().__init__()\n",
    "        self.size=224\n",
    "        self.files = self.initPaths(limit, train)\n",
    "        self.binary = binary\n",
    "        self.train = train\n",
    "        self.classes = self.initClasses() if not binary else self.initClassesCatDog()\n",
    "        # TODO: fix transforms better\n",
    "        self.transform = self.getTransform()\n",
    "        self.augTransform = self.getAugTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i, stats=False):\n",
    "        path = \"./data/images/\" + self.files[i]\n",
    "        if stats:\n",
    "            img = open_image(path)\n",
    "        else:\n",
    "            if self.files[i][0:3] == \"AUG\":\n",
    "                img = self.augTransform(open_image(\"./data/images/\" + self.files[i][3:]))\n",
    "            else:\n",
    "                img = self.transform(open_image(path))\n",
    "        class_idx = self.classes.index(self.getClass(self.files[i]))\n",
    "\n",
    "        return img, class_idx\n",
    "    \n",
    "    def getTransform(self):\n",
    "        return transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ]) # normalization ABC\n",
    "        \n",
    "    def getAugTransform(self):\n",
    "        return transforms.Compose([transforms.RandomHorizontalFlip(p = 0.7), \n",
    "                                    transforms.RandomRotation(degrees=(-30,30)),\n",
    "                                    transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ]) # normalization ABC\n",
    "\n",
    "    \n",
    "    def getCenterBoundingBox(self, fileName):\n",
    "        try:\n",
    "            file = minidom.parse('./annotations/xmls/'+fileName.replace(\".jpg\", '.xml'))\n",
    "            xmin = file.getElementsByTagName('xmin')[0].firstChild.data\n",
    "            xmax = file.getElementsByTagName('xmax')[0].firstChild.data\n",
    "            ymin = file.getElementsByTagName('ymin')[0].firstChild.data\n",
    "            ymax = file.getElementsByTagName('ymax')[0].firstChild.data\n",
    "            return int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "        except:\n",
    "            return 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    def getStats(self):\n",
    "        avgImage = th.Tensor(np.zeros((self.size, self.size, 3)))\n",
    "        \n",
    "        for i in range(self.__len__()):\n",
    "            img,_ = self.__getitem__(i, stats=True)\n",
    "            t = transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    ]) \n",
    "            avgImage += t(img)\n",
    "            \n",
    "        \n",
    "        avgImage /= self.__len__()\n",
    "        \n",
    "        mean = []\n",
    "        std = []\n",
    "        for dimension in enumerate(avgImage):\n",
    "            print(dimension)\n",
    "            mean.append(th.mean(dimension))\n",
    "            std.append(th.std(dimension))\n",
    "        \n",
    "        print(mean, std)\n",
    "            \n",
    "        \n",
    "        # return [mean[1], mean[2], mean[3]], [std[1], std[2], std[3]]\n",
    "        \n",
    "    def getCropStats(self):\n",
    "        x = 0\n",
    "        y = 0\n",
    "        n = 0\n",
    "        x_li = []\n",
    "        y_li = []\n",
    "        \n",
    "        for file in self.files:\n",
    "            xmin, xmax, ymin, ymax = self.getCenterBoundingBox(file)\n",
    "            if (xmin != 0) and (xmax != 0) and (ymin != 0) and (ymax != 0):\n",
    "                n += 1\n",
    "                \n",
    "                x += (xmax + xmin)/2\n",
    "                y += (ymax + ymin)/2\n",
    "                \n",
    "                x_li.append(x)\n",
    "                y_li.append(y)\n",
    "                \n",
    "        print(\"Average x:\", x/n, \"Average y:\", y/n)\n",
    "        \n",
    "        x_np = np.asarray(x_li)\n",
    "        y_np = np.asarray(y_li)\n",
    "        \n",
    "        x_std = np.std(x_np)\n",
    "        y_std = np.std(y_np)\n",
    "        print(\"STD x:\", x_std, \"STD y:\", y_std)\n",
    "            \n",
    "            \n",
    "    # Classifies data into Cat/Dog or into one of the 37 classes of breeds\n",
    "    def getClass(self, fileName):\n",
    "        fileName = self.cleanFileName(fileName)\n",
    "        self.getCenterBoundingBox(fileName)\n",
    "        if self.binary:\n",
    "            return self.getClassCatDog(fileName)\n",
    "        else:\n",
    "            nameList = fileName.split(\"_\")\n",
    "            name = \"\"\n",
    "            for namePart in nameList:\n",
    "                if \".jpg\" not in namePart:\n",
    "                    name += namePart\n",
    "            return name\n",
    "        \n",
    "    def initClasses(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return classList\n",
    "    \n",
    "    def getClassCatDog(self, fileName):\n",
    "       if fileName[0].isupper():\n",
    "           return \"cat\"\n",
    "       else:\n",
    "           return \"dog\"\n",
    "    \n",
    "    def initClassesCatDog(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            fname = self.cleanFileName(fname)\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return [\"cat\", \"dog\"]\n",
    "    \n",
    "    \n",
    "    def addAugmented(self, jpgList):\n",
    "        newJpgList = jpgList.copy()\n",
    "        for jpg in jpgList: # Doubles the ammount of data \n",
    "            newJpgList.append(\"AUG\"+jpg)\n",
    "\n",
    "        return newJpgList\n",
    "    \n",
    "    def initPaths(self, limit, train):\n",
    "        files = os.listdir(\"./data/images/\")\n",
    "        jpgList = []\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                jpgList.append(file)\n",
    "        \n",
    "        random.shuffle(jpgList)\n",
    "        \n",
    "        if train:\n",
    "            jpgList = jpgList[:int(len(jpgList)*0.7)]\n",
    "            jpgList = self.addAugmented(jpgList)\n",
    "            random.shuffle(jpgList)\n",
    "        else:\n",
    "            jpgList = jpgList[int(len(jpgList)*0.7):]\n",
    "        \n",
    "        return jpgList[0:int(len(jpgList)*limit)]\n",
    "\n",
    "    def cleanFileName(self,name):\n",
    "        if name[0:3] == \"AUG\":\n",
    "           return name[3:]\n",
    "        return name\n",
    "    \n",
    "\n",
    "test = MyDataset(False)\n",
    "# test.getCropStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10346 1109 1108\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "def initDataset(batch_size, binary): #batch size affects computation time\n",
    "    train = MyDataset(binary, train=True)\n",
    "    testValDataset = MyDataset(binary, train=False)\n",
    "    # Train/Validation/Test split. Current: 70/15/15\n",
    "\n",
    "    # train, test = random_split(dataset, [int(0.85*len(dataset))+1, int(0.15*len(dataset))])\n",
    "    valid, test = random_split(testValDataset, [int(0.5*len(testValDataset))+1, int(0.5*len(testValDataset))]) \n",
    "    \n",
    "    print(len(train), len(valid), len(test))\n",
    "    # print(len(train)+ len(valid)+ len(test), len(dataset))\n",
    "    \n",
    "    # Enable augementation for the training dataset\n",
    "    # augmentedDataset = AugmentedDataset(train)\n",
    "    \n",
    "    train_loader = th.utils.data.DataLoader(train,\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    \n",
    "    test_loader = th.utils.data.DataLoader(test,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    valid_loader = th.utils.data.DataLoader(valid,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    \n",
    "    return train_loader , test_loader, valid_loader\n",
    "\n",
    "train_loader, test_loader, valid_loader = initDataset(batch_size=32, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "n2 = 0\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    n += 32\n",
    "    print(n)\n",
    "    \n",
    "    if n == 64:\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        for i in range(len(images)):\n",
    "            n2+=1\n",
    "            plt.imshow(images[i].permute(1, 2, 0))\n",
    "            plt.show()\n",
    "            print(labels[i])\n",
    "            if n2 == 1:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(progress = True, pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set requires_grad to false for every layer\n",
    "moreLayers = True\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modules = model.named_modules()\n",
    "\n",
    "for i in modules:\n",
    "    if isinstance(i[1], th.nn.BatchNorm2d):\n",
    "        if \"layer4\" in i[0] and \"bn\" in i[0]:\n",
    "            i[1].momentum = 0.2\n",
    "    \n",
    "# Replace the last layer of the pretrained model with our own:\n",
    "# This should theoretically only set the last layer to requires_grad = True, since it is the default setting\n",
    "model.fc = th.nn.Linear(model.fc.in_features, 37) # 37 if not binary\n",
    "\n",
    "# Set the second layer to requires_grad = True\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# Replace more layers:\n",
    "# TODO: implement\n",
    "\n",
    "# Examine different learning rates / rate schedulers\n",
    "# TODO: implement\n",
    "\n",
    "# Apply data augmentation during training (flip, small rotations, crops, small size scaling)\n",
    "# TODO: implement\n",
    "\n",
    "# Effect of fine-tuning or not the batch-norm parameters and updating the estimate of the batch \n",
    "# mean and standard deviations on the final performance on the new dataset.\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/324 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 45 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d9e98cd32e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# new = train_model(model, train_loader, valid_loader, epochs=20, lr=10**-3 , weight_decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheduler_gamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;31m#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-4, weight_decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d9e98cd32e9d>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, valid_loader, epochs, lr, weight_decay, sheduler_gamma)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Reset the gradients, maybe we should not do this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2994\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2996\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 45 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Train the model on our dataset\n",
    "def train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0, sheduler_gamma=0.9):\n",
    "    # Define the loss function\n",
    "    criterion = th.nn.CrossEntropyLoss()\n",
    "    # Define the optimizer\n",
    "    optimizer = th.optim.Adam(model.fc.parameters(), lr=lr, weight_decay=weight_decay) # filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    \n",
    "    # Set different learning rates for different layers\n",
    "    optimizer.add_param_group({'params': model.layer4.parameters(), 'lr': lr/10})\n",
    "    \n",
    "    # Train the model\n",
    "    scheduler = th.optim.lr_scheduler.ExponentialLR(optimizer, gamma=sheduler_gamma)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train() #trains model\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad() # Reset the gradients, maybe we should not do this\n",
    "            loss.backward() # Compute the gradients\n",
    "            optimizer.step() # Update the weights\n",
    "        # Validation\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        with th.no_grad(): # Disables tracking of calculations required to calculate gradients\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, batch in enumerate(valid_loader):\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                #print(labels)\n",
    "                outputs = model(images)\n",
    "                #print(outputs)\n",
    "                _, predicted = th.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print('Learning rate: {} \\n'.format(lr))\n",
    "            print('Accuracy of the network on the validation images: {} %'.format(100 * correct / total))\n",
    "            \n",
    "    return model\n",
    "\n",
    "# new = train_model(model, train_loader, valid_loader, epochs=20, lr=10**-3 , weight_decay=0.0)\n",
    "new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-2, weight_decay=0.0, sheduler_gamma=0.5)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-4, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = train_model(model, train_loader, valid_loader, epochs=10, lr=10**-3, weight_decay=0.0,sheduler_gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = train_model(model, train_loader, valid_loader, epochs=10, lr=10**-3, weight_decay=0.0, sheduler_gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new3 = train_model(model, train_loader, valid_loader, epochs=20, lr=10**-4, weight_decay=0.0, sheduler_gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestones:\n",
    "## Grade E:\n",
    "- [x] Achieve >99% on binary classification\n",
    "- [ ] Achieve >95% on multi-class classification\n",
    "- [x] Examine fine tuning more layers\n",
    "- [x] Examine different learning rates\n",
    "- [x] Examine data augmentation\n",
    "- [-] Fine tune batch-norm\n",
    "\n",
    "## Grade A:\n",
    "### Decrease the percentage of labelled data: \n",
    "- [ ] 50 %\n",
    "- [ ] 10 %\n",
    "- [ ] 1 %\n",
    "- [ ] Implement Pseudo-labelling\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89627e806f793b932dfe80791ab48950fda4fb8e20d46d5d1c8fbf2fdce875b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
