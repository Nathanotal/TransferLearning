{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install torch\n",
    "# %pip install torchvision\n",
    "# %pip install helper\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Maybe normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def open_image(path): # https://jovian.ai/aakashns/transfer-learning-pytorch\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, binary=False, limit=1):\n",
    "        super().__init__()\n",
    "        self.size=224\n",
    "        self.files = self.initPaths(limit)\n",
    "        self.binary = binary\n",
    "        self.classes = self.initClasses() if not binary else self.initClassesCatDog()\n",
    "        # TODO: fix transforms better\n",
    "        self.transform = transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(), # Change this so we undertand\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ]) # normalization ABC\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path = \"../Datasets/images.tar/images/images/\" + self.files[i]\n",
    "        img = self.transform(open_image(path))\n",
    "        class_idx = self.classes.index(self.getClass(self.files[i]))\n",
    "        \n",
    "        #TEMP\n",
    "        \n",
    "        return img, class_idx\n",
    "    \n",
    "    \n",
    "    def getCenterBoundingBox(self, fileName):\n",
    "        try:\n",
    "            file = minidom.parse('../Datasets/annotations.tar/annotations/annotations/xmls/'+fileName.replace(\".jpg\", '.xml'))\n",
    "            xmin = file.getElementsByTagName('xmin')[0].firstChild.data\n",
    "            xmax = file.getElementsByTagName('xmax')[0].firstChild.data\n",
    "            ymin = file.getElementsByTagName('ymin')[0].firstChild.data\n",
    "            ymax = file.getElementsByTagName('ymax')[0].firstChild.data\n",
    "            return int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "        except:\n",
    "            return 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    def getCropStats(self):\n",
    "        x = 0\n",
    "        y = 0\n",
    "        n = 0\n",
    "        x_li = []\n",
    "        y_li = []\n",
    "        \n",
    "        for file in self.files:\n",
    "            xmin, xmax, ymin, ymax = self.getCenterBoundingBox(file)\n",
    "            if (xmin != 0) and (xmax != 0) and (ymin != 0) and (ymax != 0):\n",
    "                n += 1\n",
    "                \n",
    "                x += (xmax + xmin)/2\n",
    "                y += (ymax + ymin)/2\n",
    "                \n",
    "                x_li.append(x)\n",
    "                y_li.append(y)\n",
    "                \n",
    "        print(\"Average x:\", x/n, \"Average y:\", y/n)\n",
    "        \n",
    "        x_np = np.asarray(x_li)\n",
    "        y_np = np.asarray(y_li)\n",
    "        \n",
    "        x_std = np.std(x_np)\n",
    "        y_std = np.std(y_np)\n",
    "        print(\"STD x:\", x_std, \"STD y:\", y_std)\n",
    "            \n",
    "            \n",
    "    # Classifies data into Cat/Dog or into one of the 37 classes of breeds\n",
    "    def getClass(self, fileName):\n",
    "        self.getCenterBoundingBox(fileName)\n",
    "        if self.binary:\n",
    "            return self.getClassCatDog(fileName)\n",
    "        else:\n",
    "            nameList = fileName.split(\"_\")\n",
    "            name = \"\"\n",
    "            for namePart in nameList:\n",
    "                if \".jpg\" not in namePart:\n",
    "                    name += namePart\n",
    "            return name\n",
    "        \n",
    "    def initClasses(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return classList\n",
    "    \n",
    "    def getClassCatDog(self, fileName):\n",
    "       if fileName[0].isupper():\n",
    "           return \"cat\"\n",
    "       else:\n",
    "           return \"dog\"\n",
    "    \n",
    "    def initClassesCatDog(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return [\"cat\", \"dog\"]\n",
    "    \n",
    "    def initPaths(self, limit):\n",
    "        files = os.listdir(\"../Datasets/images.tar/images/images/\")\n",
    "        jpgList = []\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                jpgList.append(file)\n",
    "        random.shuffle(jpgList)\n",
    "        return jpgList[0:int(len(jpgList)*limit)]\n",
    "    \n",
    "\n",
    "test = MyDataset(False)\n",
    "# test.getCropStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "def initDataset(batch_size, binary): #batch size affects computation time\n",
    "    dataset = MyDataset(binary)\n",
    "    # Train/Validation/Test split. Current: 70/15/15\n",
    "    train, test = random_split(dataset, [int(0.85*len(dataset))+1, int(0.15*len(dataset))])\n",
    "    valid, train = random_split(train, [int(0.176*len(train))+1, int((1-0.176)*len(train))]) # Rounding error\n",
    "    \n",
    "    # print(len(train), len(valid), len(test))\n",
    "    # print(len(train)+ len(valid)+ len(test), len(dataset))\n",
    "    \n",
    "    train_loader = th.utils.data.DataLoader(train,\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    test_loader = th.utils.data.DataLoader(test,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    valid_loader = th.utils.data.DataLoader(valid,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    \n",
    "    return train_loader , test_loader, valid_loader\n",
    "\n",
    "train_loader, test_loader, valid_loader = initDataset(batch_size=32, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     images = batch[0]\n",
    "#     labels = batch[1]\n",
    "\n",
    "\n",
    "#     for i in range(len(images)):\n",
    "#         plt.imshow(images[i].permute(1, 2, 0))\n",
    "#         plt.show()\n",
    "#         print(labels[i])\n",
    "#         n += 1\n",
    "#         if n == 1:\n",
    "#             break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(progress = True, pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set requires_grad to false for every layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Replace the last layer of the pretrained model with our own:\n",
    "#This should theoretically only set the last layer to requires_grad = True, since it is the default setting\n",
    "model.fc = th.nn.Linear(model.fc.in_features, 2) # 37 if not binary\n",
    "\n",
    "\n",
    "# Replace more layers:\n",
    "# TODO: implement\n",
    "\n",
    "# Examine different learning rates / rate schedulers\n",
    "# TODO: implement\n",
    "\n",
    "# Apply data augmentation during training (flip, small rotations, crops, small size scaling)\n",
    "# TODO: implement\n",
    "\n",
    "# Effect of fine-tuning or not the batch-norm parameters and updating the estimate of the batch \n",
    "# mean and standard deviations on the final performance on the new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:41<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 98.4629294755877 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:35<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 98.28209764918626 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:25<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 98.8245931283906 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [05:04<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.36708860759494 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:25<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.09584086799276 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:31<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.54792043399638 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:09<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.45750452079567 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:12<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.00542495479205 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:07<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.18625678119349 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:09<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.36708860759494 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:11<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.36708860759494 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:02<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 98.91500904159132 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:02<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.54792043399638 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:45<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.36708860759494 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:48<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.63833634719711 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:43<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.45750452079567 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:45<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.72875226039783 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:20<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.45750452079567 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:49<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.72875226039783 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [04:37<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 99.54792043399638 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model on our dataset\n",
    "def train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0):\n",
    "    # Define the loss function\n",
    "    criterion = th.nn.CrossEntropyLoss()\n",
    "    # Define the optimizer\n",
    "    optimizer = th.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train() #trains model\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad() # Reset the gradients, maybe we should not do this\n",
    "            loss.backward() # Compute the gradients\n",
    "            optimizer.step() # Update the weights\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with th.no_grad(): # Disables tracking of calculations required to calculate gradients\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, batch in enumerate(valid_loader):\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                #print(labels)\n",
    "                outputs = model(images)\n",
    "                #print(outputs)\n",
    "                _, predicted = th.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print('Learning rate: {} \\n'.format(lr))\n",
    "            print('Accuracy of the network on the validation images: {} %'.format(100 * correct / total))\n",
    "            \n",
    "    return model\n",
    "\n",
    "new = train_model(model, train_loader, valid_loader, epochs=20, lr=10**-3 , weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-2, weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-4, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestones:\n",
    "## Grade E:\n",
    "- [ ] Achieve >99% on binary classification\n",
    "- [ ] Achieve >95% on multi-class classification\n",
    "- [ ] Examine fine tuning more layers\n",
    "- [ ] Examine different learning rates\n",
    "- [ ] Examine data augmentation\n",
    "- [ ] Fine tune batch-norm\n",
    "\n",
    "## Grade A:\n",
    "### Decrease the percentage of labelled data: \n",
    "- [ ] 50 %\n",
    "- [ ] 10 %\n",
    "- [ ] 1 %\n",
    "- [ ] Implement Pseudo-labelling\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59b8bae32ae535ad7f778145d834fc75c2d3e41fc284115aa6b25c7fb41e16b4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
