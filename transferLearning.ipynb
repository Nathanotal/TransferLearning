{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install torch\n",
    "# %pip install torchvision\n",
    "# %pip install helper\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Maybe normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as tttttt\n",
    "import random\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "def open_image(path): # https://jovian.ai/aakashns/transfer-learning-pytorch\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.standardImagesAdded = 0\n",
    "        self.length = len(subset.dataset)\n",
    "        self.subset = th.utils.data.ConcatDataset([subset, subset]) # Add data\n",
    "        self.transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                            # transforms.RandomRotation(degrees=(-30, 30)),\n",
    "                                            transforms.Resize(255),\n",
    "                                            transforms.CenterCrop(224), \n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]) # normalization ABC\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if ((self.standardImagesAdded % self.length*2) < self.length): # Add standard images\n",
    "            self.standardImagesAdded += 1\n",
    "            return self.subset[index]\n",
    "        \n",
    "        # Add augmented images\n",
    "        x, y = self.subset[index]\n",
    "        t = tttttt.ToPILImage()\n",
    "        x = self.transform(t(x)) \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, binary=False, limit=1):\n",
    "        super().__init__()\n",
    "        self.size=224\n",
    "        self.files = self.initPaths(limit)\n",
    "        self.binary = binary\n",
    "        self.classes = self.initClasses() if not binary else self.initClassesCatDog()\n",
    "        # TODO: fix transforms better\n",
    "        self.transform = self.getTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i, stats=False):\n",
    "        path = \"./data/images/\" + self.files[i]\n",
    "        if stats:\n",
    "            img = open_image(path)\n",
    "        else:\n",
    "            img = self.transform(open_image(path))\n",
    "        class_idx = self.classes.index(self.getClass(self.files[i]))\n",
    "\n",
    "        return img, class_idx\n",
    "    \n",
    "    def getTransform(self):\n",
    "        return transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ]) # normalization ABC\n",
    "\n",
    "    \n",
    "    def getCenterBoundingBox(self, fileName):\n",
    "        try:\n",
    "            file = minidom.parse('./annotations/xmls/'+fileName.replace(\".jpg\", '.xml'))\n",
    "            xmin = file.getElementsByTagName('xmin')[0].firstChild.data\n",
    "            xmax = file.getElementsByTagName('xmax')[0].firstChild.data\n",
    "            ymin = file.getElementsByTagName('ymin')[0].firstChild.data\n",
    "            ymax = file.getElementsByTagName('ymax')[0].firstChild.data\n",
    "            return int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "        except:\n",
    "            return 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "    def getStats(self):\n",
    "        avgImage = th.Tensor(np.zeros((self.size, self.size, 3)))\n",
    "        \n",
    "        for i in range(self.__len__()):\n",
    "            img,_ = self.__getitem__(i, stats=True)\n",
    "            t = transforms.Compose([transforms.Resize(255),\n",
    "                                    transforms.CenterCrop(224), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    ]) \n",
    "            avgImage += t(img)\n",
    "            \n",
    "        \n",
    "        avgImage /= self.__len__()\n",
    "        \n",
    "        mean = []\n",
    "        std = []\n",
    "        for dimension in enumerate(avgImage):\n",
    "            print(dimension)\n",
    "            mean.append(th.mean(dimension))\n",
    "            std.append(th.std(dimension))\n",
    "        \n",
    "        print(mean, std)\n",
    "            \n",
    "        \n",
    "        # return [mean[1], mean[2], mean[3]], [std[1], std[2], std[3]]\n",
    "            \n",
    "    \n",
    "    def getCropStats(self):\n",
    "        x = 0\n",
    "        y = 0\n",
    "        n = 0\n",
    "        x_li = []\n",
    "        y_li = []\n",
    "        \n",
    "        for file in self.files:\n",
    "            xmin, xmax, ymin, ymax = self.getCenterBoundingBox(file)\n",
    "            if (xmin != 0) and (xmax != 0) and (ymin != 0) and (ymax != 0):\n",
    "                n += 1\n",
    "                \n",
    "                x += (xmax + xmin)/2\n",
    "                y += (ymax + ymin)/2\n",
    "                \n",
    "                x_li.append(x)\n",
    "                y_li.append(y)\n",
    "                \n",
    "        print(\"Average x:\", x/n, \"Average y:\", y/n)\n",
    "        \n",
    "        x_np = np.asarray(x_li)\n",
    "        y_np = np.asarray(y_li)\n",
    "        \n",
    "        x_std = np.std(x_np)\n",
    "        y_std = np.std(y_np)\n",
    "        print(\"STD x:\", x_std, \"STD y:\", y_std)\n",
    "            \n",
    "            \n",
    "    # Classifies data into Cat/Dog or into one of the 37 classes of breeds\n",
    "    def getClass(self, fileName):\n",
    "        self.getCenterBoundingBox(fileName)\n",
    "        if self.binary:\n",
    "            return self.getClassCatDog(fileName)\n",
    "        else:\n",
    "            nameList = fileName.split(\"_\")\n",
    "            name = \"\"\n",
    "            for namePart in nameList:\n",
    "                if \".jpg\" not in namePart:\n",
    "                    name += namePart\n",
    "            return name\n",
    "        \n",
    "    def initClasses(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return classList\n",
    "    \n",
    "    def getClassCatDog(self, fileName):\n",
    "       if fileName[0].isupper():\n",
    "           return \"cat\"\n",
    "       else:\n",
    "           return \"dog\"\n",
    "    \n",
    "    def initClassesCatDog(self):\n",
    "        classList = []\n",
    "        for fname in self.files:\n",
    "            theClass = self.getClass(fname)\n",
    "            if theClass not in classList:\n",
    "                classList.append(theClass)\n",
    "        return [\"cat\", \"dog\"]\n",
    "    \n",
    "    def initPaths(self, limit):\n",
    "        files = os.listdir(\"./data/images/\")\n",
    "        jpgList = []\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                jpgList.append(file)\n",
    "        random.shuffle(jpgList)\n",
    "        return jpgList[0:int(len(jpgList)*limit)]\n",
    "    \n",
    "\n",
    "test = MyDataset(False)\n",
    "# test.getCropStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "def initDataset(batch_size, binary): #batch size affects computation time\n",
    "    dataset = MyDataset(binary)\n",
    "    # Train/Validation/Test split. Current: 70/15/15\n",
    "    train, test = random_split(dataset, [int(0.85*len(dataset))+1, int(0.15*len(dataset))])\n",
    "    valid, train = random_split(train, [int(0.176*len(train))+1, int((1-0.176)*len(train))]) # Rounding error\n",
    "    \n",
    "    # print(len(train), len(valid), len(test))\n",
    "    # print(len(train)+ len(valid)+ len(test), len(dataset))\n",
    "    \n",
    "    # Enable augementation for the training dataset\n",
    "    augmentedDataset = AugmentedDataset(train)\n",
    "    \n",
    "    train_loader = th.utils.data.DataLoader(augmentedDataset,\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "    \n",
    "    test_loader = th.utils.data.DataLoader(test,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    valid_loader = th.utils.data.DataLoader(valid,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    \n",
    "    return train_loader , test_loader, valid_loader\n",
    "\n",
    "train_loader, test_loader, valid_loader = initDataset(batch_size=32, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# n2 = 0\n",
    "# for batch_idx, batch in enumerate(train_loader):\n",
    "#     n += 32\n",
    "#     print(n)\n",
    "    \n",
    "#     if n == 8000:\n",
    "#         images = batch[0]\n",
    "#         labels = batch[1]\n",
    "#         for i in range(len(images)):\n",
    "#             n2+=1\n",
    "#             plt.imshow(images[i].permute(1, 2, 0))\n",
    "#             plt.show()\n",
    "#             print(labels[i])\n",
    "#             if n2 == 1:\n",
    "#                 break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(progress = True, pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set requires_grad to false for every layer\n",
    "moreLayers = True\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modules = model.named_modules()\n",
    "\n",
    "for i in modules:\n",
    "    if isinstance(i[1], th.nn.BatchNorm2d):\n",
    "        if \"layer4\" in i[0] and \"bn\" in i[0]:\n",
    "            i[1].momentum = 0.20\n",
    "    \n",
    "# Replace the last layer of the pretrained model with our own:\n",
    "# This should theoretically only set the last layer to requires_grad = True, since it is the default setting\n",
    "model.fc = th.nn.Linear(model.fc.in_features, 37) # 37 if not binary\n",
    "\n",
    "# Set the second layer to requires_grad = True\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# Replace more layers:\n",
    "# TODO: implement\n",
    "\n",
    "# Examine different learning rates / rate schedulers\n",
    "# TODO: implement\n",
    "\n",
    "# Apply data augmentation during training (flip, small rotations, crops, small size scaling)\n",
    "# TODO: implement\n",
    "\n",
    "# Effect of fine-tuning or not the batch-norm parameters and updating the estimate of the batch \n",
    "# mean and standard deviations on the final performance on the new dataset.\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [38:03<00:00,  7.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001 \n",
      "\n",
      "Accuracy of the network on the validation images: 5.244122965641953 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/324 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-ba1e94ea45bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;31m#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-2, weight_decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-ba1e94ea45bf>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, valid_loader, epochs, lr, weight_decay)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2419\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2421\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2422\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model on our dataset\n",
    "def train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0):\n",
    "    # Define the loss function\n",
    "    criterion = th.nn.CrossEntropyLoss()\n",
    "    # Define the optimizer\n",
    "    optimizer = th.optim.Adam(model.fc.parameters(), lr=lr, weight_decay=weight_decay) # filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    \n",
    "    # Set different learning rates for different layers\n",
    "    optimizer.add_param_group({'params': model.layer4.parameters(), 'lr': lr/10})\n",
    "    \n",
    "    # Train the model\n",
    "    # scheduler = th.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train() #trains model\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad() # Reset the gradients, maybe we should not do this\n",
    "            loss.backward() # Compute the gradients\n",
    "            optimizer.step() # Update the weights\n",
    "        # Validation\n",
    "        # scheduler.step()\n",
    "        model.eval()\n",
    "        with th.no_grad(): # Disables tracking of calculations required to calculate gradients\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, batch in enumerate(valid_loader):\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                #print(labels)\n",
    "                outputs = model(images)\n",
    "                #print(outputs)\n",
    "                _, predicted = th.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print('Learning rate: {} \\n'.format(lr))\n",
    "            print('Accuracy of the network on the validation images: {} %'.format(100 * correct / total))\n",
    "            \n",
    "    return model\n",
    "\n",
    "new = train_model(model, train_loader, valid_loader, epochs=20, lr=10**-3 , weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-2, weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-3, weight_decay=0.0)\n",
    "#new = train_model(model, train_loader, valid_loader, epochs=5, lr=10**-4, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestones:\n",
    "## Grade E:\n",
    "- [x] Achieve >99% on binary classification\n",
    "- [ ] Achieve >95% on multi-class classification\n",
    "- [x] Examine fine tuning more layers\n",
    "- [x] Examine different learning rates\n",
    "- [x] Examine data augmentation\n",
    "- [-] Fine tune batch-norm\n",
    "\n",
    "## Grade A:\n",
    "### Decrease the percentage of labelled data: \n",
    "- [ ] 50 %\n",
    "- [ ] 10 %\n",
    "- [ ] 1 %\n",
    "- [ ] Implement Pseudo-labelling\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89627e806f793b932dfe80791ab48950fda4fb8e20d46d5d1c8fbf2fdce875b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
